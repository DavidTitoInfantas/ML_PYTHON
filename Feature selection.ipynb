{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder #, SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "     \n",
    "\n",
    "# Carregando o dataset\n",
    "# URL do conjunto de dados Titanic\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "\n",
    "# Importando o conjunto de dados\n",
    "df = pd.read_csv(url)\n",
    "df = df.rename(columns={'Survived': 'Target'})\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket'])\n",
    "\n",
    "# Selecionando as variáveis\n",
    "features = [x for x in list(df.columns) if x not in ['Target']] # Exclui a coluna target\n",
    "target = ['Target']\n",
    "\n",
    "# Pré-processamento\n",
    "# Imputação de valores missing\n",
    "colunas_numericas = list(df.select_dtypes(include=['number']).columns)\n",
    "colunas_numericas.remove('Target')\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# imputer.fit(df[features])\n",
    "\n",
    "# Transformação de variáveis categóricas\n",
    "categorical_features = list(df.select_dtypes(include=['category', 'object']).columns)\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# onehot_encoder.fit(df[categorical_features])\n",
    "\n",
    "# Pré-processamento em pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('imputer', imputer, colunas_numericas),\n",
    "    ('onehot', onehot_encoder, categorical_features)\n",
    "])\n",
    "df_processado = pd.DataFrame(preprocessor.fit_transform(df[features]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boruta\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "###initialize Boruta\n",
    " \n",
    "def boruta(X,y):\n",
    "  forest = RandomForestRegressor(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 5)\n",
    "  boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 100 # number of trials to perform\n",
    "                  )\n",
    "### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "  boruta.fit(np.array(X), np.array(y))\n",
    "### print results\n",
    "  green_area = X.columns[boruta.support_].to_list()\n",
    "  blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "  print('features in the green area:', green_area)\n",
    "  print('='*80)\n",
    "  print('features in the blue area:', blue_area)\n",
    "  return green_area\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "boruta_feauter = boruta(X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.218110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.206602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.139361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.114807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.066755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>72</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>48</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>111</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name  feature_importance\n",
       "0               1            0.218110\n",
       "1               4            0.206602\n",
       "2               6            0.139361\n",
       "3               5            0.114807\n",
       "4               0            0.066755\n",
       "..            ...                 ...\n",
       "154            72            0.000055\n",
       "155            48            0.000031\n",
       "156           111            0.000019\n",
       "157            50            0.000016\n",
       "158            83            0.000009\n",
       "\n",
       "[159 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleção de variaveis utilizando o feature importance \n",
    "# feature_importances_ é quanato a variavel foi utilizada\n",
    "# \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = df_processado\n",
    "y = df['Target']\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42).fit(X, y)\n",
    "\n",
    "df_imp = \\\n",
    "(pd.DataFrame(list(zip(X.columns, rfc.feature_importances_)),\n",
    "              columns=['feature_name', 'feature_importance'])\n",
    " .sort_values(by='feature_importance', ascending=False)\n",
    " .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_permutation_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.114703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.106958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.046240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>71</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>72</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>93</td>\n",
       "      <td>-0.000112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name  feature_permutation_importance\n",
       "0               1                        0.125926\n",
       "1               4                        0.114703\n",
       "2               6                        0.106958\n",
       "3               0                        0.081818\n",
       "4               2                        0.046240\n",
       "..            ...                             ...\n",
       "154            71                        0.000000\n",
       "155            72                        0.000000\n",
       "156            61                        0.000000\n",
       "157           103                       -0.000112\n",
       "158            93                       -0.000112\n",
       "\n",
       "[159 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calcular importância de permutação\n",
    "perm_importance = permutation_importance(rfc, X, y, n_repeats=10, random_state=42)\n",
    "\n",
    "# Exibir importância de permutação das features\n",
    "df_permut_imp = \\\n",
    "(pd.DataFrame(list(zip(X.columns, perm_importance.importances_mean)),\n",
    "              columns=['feature_name', 'feature_permutation_importance'])\n",
    " .sort_values(by='feature_permutation_importance', ascending=False)\n",
    " .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_permut_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>shap_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.085388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.067428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.061784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.054476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>46</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>72</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>41</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name  shap_importance\n",
       "0               6         0.085388\n",
       "1               5         0.067428\n",
       "2               4         0.061784\n",
       "3               2         0.054476\n",
       "4               0         0.032263\n",
       "..            ...              ...\n",
       "154            46         0.000016\n",
       "155            72         0.000014\n",
       "156            50         0.000013\n",
       "157            41         0.000012\n",
       "158            83         0.000004\n",
       "\n",
       "[159 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install shap\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_vals = explainer.shap_values(X)\n",
    "# revisar  se é a media de tudo ou a media do primeiro resultado \n",
    "df_imp_shap = \\\n",
    "(pd.DataFrame(list(zip(X.columns, np.abs(shap_vals[0]).mean(axis=1))),  # np.abs(shap_vals).mean(axis=0).mean(axis=1))\n",
    "              columns=['feature_name', 'shap_importance'])   \n",
    " .sort_values(by='shap_importance', ascending=False)\n",
    "  .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_imp_shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m rfc \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m      6\u001b[0m    n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      7\u001b[0m    max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m boruta \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     10\u001b[0m (BorutaPy(\n\u001b[1;32m     11\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrfc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m  ) \u001b[38;5;66;03m# fit accepts np.array, not pd.DataFrame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mboruta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Analitico_base/lib/python3.10/site-packages/boruta/boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Analitico_base/lib/python3.10/site-packages/boruta/boruta_py.py:260\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# holds the decision about each feature:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# 0  - default state = tentative in original code\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# 1  - accepted in original code\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# -1 - rejected in original code\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m dec_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# counts how many times a given feature was more important than\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# the best of the shadow features\u001b[39;00m\n\u001b[1;32m    263\u001b[0m hit_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:313\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    308\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "\n",
    "from boruta import BorutaPy\n",
    "X = df_processado\n",
    "y = df['Target']\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 5)\n",
    "\n",
    "boruta = \\\n",
    "(BorutaPy(\n",
    "    estimator=rfc,\n",
    "    n_estimators=50,\n",
    "    max_iter=100, # number of trials to perform\n",
    "    random_state=42)\n",
    " ) # fit accepts np.array, not pd.DataFrame\n",
    "\n",
    "boruta.fit(np.array(X), np.array(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 28\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures in the blue area:\u001b[39m\u001b[38;5;124m'\u001b[39m, blue_area)\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m green_area\n\u001b[0;32m---> 28\u001b[0m boruta_feauter \u001b[38;5;241m=\u001b[39m \u001b[43mboruta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 16\u001b[0m, in \u001b[0;36mboruta\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m   boruta \u001b[38;5;241m=\u001b[39m BorutaPy(\n\u001b[1;32m     11\u001b[0m    estimator \u001b[38;5;241m=\u001b[39m forest, \n\u001b[1;32m     12\u001b[0m    n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m    max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m# number of trials to perform\u001b[39;00m\n\u001b[1;32m     14\u001b[0m                   )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m### fit Boruta (it accepts np.array, not pd.DataFrame)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m   \u001b[43mboruta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m### print results\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   green_area \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[boruta\u001b[38;5;241m.\u001b[39msupport_]\u001b[38;5;241m.\u001b[39mto_list()\n",
      "File \u001b[0;32m~/anaconda3/envs/Analitico_base/lib/python3.10/site-packages/boruta/boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Analitico_base/lib/python3.10/site-packages/boruta/boruta_py.py:260\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# holds the decision about each feature:\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# 0  - default state = tentative in original code\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# 1  - accepted in original code\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# -1 - rejected in original code\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m dec_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# counts how many times a given feature was more important than\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# the best of the shadow features\u001b[39;00m\n\u001b[1;32m    263\u001b[0m hit_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:313\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    308\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "###initialize Boruta\n",
    " \n",
    "def boruta(X,y):\n",
    "  forest = RandomForestRegressor(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 5)\n",
    "  boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 100 # number of trials to perform\n",
    "                  )\n",
    "### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "  boruta.fit(np.array(X), np.array(y))\n",
    "### print results\n",
    "  green_area = X.columns[boruta.support_].to_list()\n",
    "  blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "  print('features in the green area:', green_area)\n",
    "  print('='*80)\n",
    "  print('features in the blue area:', blue_area)\n",
    "  return green_area\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "boruta_feauter = boruta(X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_is_fitted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# from shap_feature_importances_ import SHAPImportanceRandomForestClassifier\u001b[39;00m\n\u001b[1;32m     16\u001b[0m rfc_shap \u001b[38;5;241m=\u001b[39m SHAPImportanceRandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrfc_shap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 9\u001b[0m, in \u001b[0;36mSHAPImportanceRandomForestClassifier.feature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_importances_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     10\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     11\u001b[0m     shap_vals \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_is_fitted' is not defined"
     ]
    }
   ],
   "source": [
    "# Adaptar o atributo .feature_importances_ para o SHAP\n",
    "class SHAPImportanceRandomForestClassifier(RandomForestClassifier):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        self.X_ = X\n",
    "        super().fit(X, y, sample_weight=sample_weight)\n",
    "        return self\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        check_is_fitted(self)\n",
    "        explainer = shap.TreeExplainer(self)\n",
    "        shap_vals = explainer.shap_values(self.X_)\n",
    "        return np.abs(shap_vals[0]).mean(axis=0)\n",
    "    \n",
    "# from shap_feature_importances_ import SHAPImportanceRandomForestClassifier\n",
    "\n",
    "rfc_shap = SHAPImportanceRandomForestClassifier(random_state=42).fit(X, y)\n",
    "rfc_shap.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_selection import SelectorMixin\n",
    "\n",
    "class SelectKTop(SelectorMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, K=5, base_estimator=None, random_state=None):\n",
    "        self.K = K\n",
    "        self.base_estimator = base_estimator\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _validate_estimator(self, default):\n",
    "        if self.base_estimator is not None:\n",
    "            self.base_estimator_ = self.base_estimator\n",
    "        else:\n",
    "            self.base_estimator_ = default\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X = self._validate_data(\n",
    "            X,\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "\n",
    "        self._validate_estimator(RandomForestClassifier(random_state=self.random_state))\n",
    "\n",
    "        self.base_estimator_.fit(X, y)\n",
    "\n",
    "        self._selected_index_list_ = \\\n",
    "        (pd.DataFrame(list(zip(range(self.n_features_in_), self.base_estimator_.feature_importances_)),\n",
    "                      columns=['feature_name', 'feature_importance'])\n",
    "         .sort_values(by='feature_importance', ascending=False)\n",
    "         .head(self.K)\n",
    "         .index\n",
    "         .to_list()\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _get_support_mask(self):\n",
    "        check_is_fitted(self)\n",
    "        return np.array([feat in self._selected_index_list_ for feat in range(self.n_features_in_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SelectKTop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSelectKTop\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, RepeatedStratifiedKFold\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SelectKTop'"
     ]
    }
   ],
   "source": [
    "import SelectKTop\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "grid = (\n",
    "    GridSearchCV(\n",
    "        make_pipeline(SelectKTop(random_state=42),\n",
    "                      RandomForestClassifier(random_state=42)),\n",
    "        param_grid={'selectktop__K': np.arange(1,N_FEATURES+1)},\n",
    "        cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42),\n",
    "        scoring='roc_auc')\n",
    "    .fit(X, y))\n",
    "\n",
    "df_cv = (\n",
    "    pd.DataFrame(grid.cv_results_)[[\n",
    "        'param_selectktop__K',\n",
    "        'mean_test_score',\n",
    "        'std_test_score'\n",
    "    ]])\n",
    "\n",
    "cv_best = (\n",
    "    df_cv\n",
    "    .sort_values(by='mean_test_score', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .loc[0])\n",
    "plt.errorbar(df_cv.param_selectktop__K, df_cv.mean_test_score, 1.96*df_cv.std_test_score)\n",
    "plt.scatter(cv_best.param_selectktop__K, cv_best.mean_test_score, s=100)\n",
    "plt.ylim(0.75, 1)\n",
    "plt.xlabel('K of SelectKTop')\n",
    "plt.xticks(df_cv.param_selectktop__K.astype(int))\n",
    "plt.ylabel('Performance (ROCAUC)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Analitico_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
